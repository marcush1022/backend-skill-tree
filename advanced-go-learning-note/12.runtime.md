# **Runtime**

# **1. Goroutine 原理**
## **1.1. Goroutine**
### **1.1.1.  goroutine 定义**
- “Goroutine 是一个与其他 `goroutines 并行运行在同一地址空间`的 Go 函数或方法。一个运行的程序由一个或更多个 goroutine 组成。它与`线程、协程、进程`等不同。它是一个 goroutine” —— Rob Pike

- goroutine 其实是运行的`一小块函数一小块方法`，goroutine 只不过是`由 go 的 runtime 来托管的一小坨代码`

- `runtime.g` 是一个结构体，就像线程一样，在内核有一个 `task struct` 的结构体，结构体里面存的是`进程的信息`，`内存地址信息`从哪开始从哪结束。

- **goroutine `轻量级、开销低、用户态`，go 的 `runtime` 就是 go 的`内核`，去管 `goroutine`**。

- goroutines 在同一个`用户地址空间`里并行`独立执行 functions`，channels 则用于 goroutines 间的`通信`和`同步访问控制`。

<br>

### **1.1.2. goroutine 和 thread 的区别?**
1. **内存占用**
    
    - 创建一个 `goroutine` 的`栈内存`消耗为 `2 KB` (Linux AMD64 Go v1.4 后)，运行过程中，如果栈空间不够用，会自动进行扩容。

    - 创建一个 `thread` 为了尽量避免极端情况下操作系统线程栈的溢出，默认会为其分配一个较大的栈内存 (`1 - 8 MB 栈内存`，POSIX Thread)，而且还需要一个被称为 “`guard page`” 的区域用于和其他 thread 的栈空间进行隔离。
    
    - 而`栈内存空间`一旦创建和初始化完成之后其大小就`不能再有变化`，这决定了在某些特殊场景下系统线程栈还是`有溢出的风险`。（guard page 保护机制，避免一个线程操作了其他线程的栈）

2. **创建/销毁**
    
    - 线程`创建和销毀`都会有巨大的消耗，是`内核级的交互` (trap)。

    - 而`进入内核`所消耗的`性能代价比较高`，开销较大。goroutine 是`用户态线程`，是由 `go runtime` 管理，创建和销毁的`消耗非常小`。

3. **调度切换**
    
    - 抛开`陷入内核`，`线程切换`会消耗 `1000-1500 纳秒` (上下文保存成本高，较多寄存器，公平性，复杂时间计算统计)，一个纳秒平均可以执行 `12-18 条指令`。

    - 所以由于`线程切换`，`执行指令的条数会`减少 12000-18000。goroutine 的切换约为 `200 ns` (用户态、3个寄存器)，相当于 `2400-3600 条指令`。
    
    - 因此，goroutines `切换成本`比 threads 要小得多。

4. **复杂性**
    
    - 线程的`创建和退出复杂`，多个 thread 间`通讯复杂` (`share memory`)。

    - 不能`大量创建线程` (参考早期的 httpd)，`成本高`，使用网络多路复用，存在大量 callback (参考 twemproxy、nginx 的代码)。对于应用服务线程门槛高，例如需要做第三方库隔离，需要考虑引入`线程池`等。

    > - "go 解决什么问题呢，创建一个 goroutine，同步的处理网络的读，再创建一个 goroutine 负责写，你的代码其实是从上到下过程式的写下来的，是非常爽的。而且 goroutine 创建的成本很低，(线程模型去处理网络肯定不行)，调度切换成本也是很低的，所以 go 的 `runtime` 可以`大量创建 goroutine`，并且他的调度切换是在`用户态`实现的，`成本很低`。"

<br>    

### **1.1.3. M:N 模型**
- go 其实也是用 `linux 的线程`来利用`多核`，但是好的是可以在一个线程里`创建无数 N 个 goroutine`，这 N 个 goroutine 都可以映射到 `M 个线程`上，即 `M:N 模型`。

- 同一个时刻，一个线程只能跑一个 goroutine。当 goroutine 发生`阻塞` (`chan 阻塞、mutex、syscall` 等等) 时，Go 会把当前的 `goroutine 调度走`，让其他 goroutine 来继续执行，而不是让`线程阻塞休眠`，尽可能多的分发任务出去，让 CPU 忙。

- `go.1.15.2/src/runtime` g p m 都有定义

<br>

## **1.2. GMP 调度模型**
### **1.2.1. GMP 概念**
- `G`
    
    - `goroutine` 的缩写，每次 `go func()` 都代表一个 G，`无限制`。使用 `struct runtime.g`，包含了当前 goroutine 的`状态、堆栈、上下文`。

- `M`
    
    - `工作线程` (OS thread) 也被称为 `Machine`，使用 `struct runtime.m`，所有 M 是有`线程栈`的。
    
    - 如果不对该线程栈提供内存的话，系统会给该线程栈提供内存 (不同操作系统提供的线程栈大小不同)。当指定了线程栈，则 `M.stack → G.stack`，M 的 `PC 寄存器指向 G 提供的函数`，然后去执行。
        
        - **工作线程要执行一个 g，`g 有一个 2k 的栈`，相当于是把 `m 的栈`指向 `g 的栈`，然后 m 的 `pc (program counter) 寄存器`指向 g 提供的函数，然后就可以切到那个地方 (`goroutine 里面`) 去执行，相当于蹭`别人的栈`、别人的提供的`寄存器`，去执行`别人的代码`**

        - **当这个执行完之后，会产生一个`调度行为`，会切回自己的`系统栈`，(栈其实分两个栈，一个是`线程自己的栈`，一个是 `g 的栈`)，这个栈`执行的代码`其实是 `g0`，g0 的代码就是一坨`找可用的 goroutine` 的代码，这个代码执行是用的`自己的栈`，即 `1～8m 的线程的栈`**

    - **`g0` 其实是负责`创建、销毁、调度 goroutine`。每个`线程`都会有一个 `g0`，即`每个 m 都有一个 g0`**

<br>

### **1.2.2. GM 调度器**
- Go 1.2 前的调度器实现，限制了 Go `并发程序的伸缩性`，尤其是对那些有`高吞吐`或`并行计算`需求的服务程序。

- **以前只有 g 和 m，首先是有个`全局队列 global queue`，通过一个全局锁 `sched lock` 来把 goroutine 的任务`追加到队列里面`。sched lock 是一个`全局大锁`，所有 m 线程`拉一个任务都要抢这个锁`，所以`吞吐上不来`，因为是全局大锁**

<br>

### **1.2.3. GM 调度模型的问题**
- **单一`全局互斥锁` (Sched.Lock) 和`集中状态存储`**

    - 导致所有 goroutine 相关操作，比如: `创建、重新调度等都要上锁`。

- **Goroutine `传递问题`**

    - M 经常在 M 之间传递`可运行`的 goroutine，这导致调度延迟增大以及额外的性能损耗。

    - 比如 m 这个 g 执行到一个地方可能堵住了，比如`加锁`或者`读 channel`，要把它`交换出来`，`放回队列里`，然后就有可能`被其他的 m 拿走`。所以就是一个可运行的 g 会在`两个 m 来回的执行`，还要`加锁`，调度延迟是非常大的

- **Per-M 持有`内存缓存` (`M.mcache`)**

    - 类似 TCMalloc 的结构，每个 M 持有 `mcache` 和 `stack alloc`，然而只有在 `M 运行 Go 代码时`才需要使用 cache (每个 `mcache` 可以高达 `2mb`)，当 M 在处于 `syscall 时并不需要`。`运行 Go 代码`和`阻塞在 syscall` 的 M 的比例高达 `1:100`，造成了`很大的浪费`。同时内存亲和性也较差 (proc a new proc b)。

- **严重的线程阻塞/解锁**
    
    - 在系统调用的情况下，工作线程经常被阻塞和取消阻塞，这增加了很多开销。

- **主要大问题**

    - `全局大锁` + `mcahce 是挂载在线程上面` (mcache 线程访问不需要加锁，`自己的内存`，类似`局部变量`, mcache 一般用来去锁加速)